'use strict';

/**
 * voice.js â€” Reliable voice capture via AudioContext ScriptProcessor.
 *
 * WHY not MediaRecorder â†’ decodeAudioData:
 *   MediaRecorder produces compressed webm/ogg. decodeAudioData on that
 *   blob fails silently on many Windows / Chrome / Edge setups.
 *
 * SOLUTION:
 *   ScriptProcessor captures raw Float32 PCM directly from the mic at the
 *   browser's native rate â†’ we resample to 16 kHz mono â†’ write PCM-16 WAV
 *   â†’ POST to Flask â†’ Vosk transcribes it reliably.
 */

// â”€â”€ State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let audioCtx        = null;   // created ONCE on first user gesture, never closed
let nativeSampleRate = 44100; // set when audioCtx is created
let scriptProcessor = null;
let micSource       = null;
let micStream       = null;
let pcmBuffers      = [];
let isRecording     = false;
let recordTimeout   = null;
let isSpeaking      = false;   // true while TTS audio is playing
let _ttsAudio       = null;    // reference to current <audio> element
let _emailStep      = null;    // current step of voice-guided email compose (or null)
let _wsRecog        = null;    // Web Speech API recognizer used during TTS playback

const TARGET_SAMPLE_RATE = 16000;   // Vosk requirement
const MAX_RECORD_SECONDS = 8;
const BUFFER_SIZE        = 4096;

// â”€â”€ DOM shorthand â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const $ = id => document.getElementById(id);

// â”€â”€ Entry point (onclick) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function toggleRecording() {
  // If AI is speaking, stop it â€” stopSpeaking() will auto-restart recording
  if (isSpeaking) { stopSpeaking(); return; }
  isRecording ? stopRecording() : await startRecording();
}

// â”€â”€ Initialise AudioContext (called once from first user gesture) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function _ensureAudioCtx() {
  if (!micStream || micStream.getTracks().some(t => t.readyState === 'ended')) {
    try {
      micStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount:     1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl:  true,
        },
        video: false,
      });
    } catch (err) {
      setStatus('Mic access denied: ' + err.message, 'error');
      return false;
    }
  }

  if (!audioCtx) {
    audioCtx         = new (window.AudioContext || window.webkitAudioContext)();
    nativeSampleRate = audioCtx.sampleRate;
  }

  // Browsers can suspend the ctx; resume only works inside a user-gesture call
  // (this path is always triggered by a click on first call)
  if (audioCtx.state === 'suspended') {
    try { await audioCtx.resume(); } catch (_) {}
  }

  return true;
}

// â”€â”€ Start â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function startRecording() {
  if (isRecording) return;                           // already recording

  const ready = await _ensureAudioCtx();
  if (!ready) return;

  // AudioContext might have been left suspended by the browser after TTS.
  // If so we can't resume it without a user gesture â€” just wait for next tap.
  if (audioCtx.state === 'suspended') {
    setStatus('Tap ğŸ¤ to activate microphone', 'idle');
    return;
  }

  pcmBuffers = [];

  // Fresh ScriptProcessor each recording (they can't be reused across recordings)
  if (scriptProcessor) { scriptProcessor.disconnect(); scriptProcessor = null; }
  if (micSource)       { micSource.disconnect();       micSource = null; }

  micSource       = audioCtx.createMediaStreamSource(micStream);
  scriptProcessor = audioCtx.createScriptProcessor(BUFFER_SIZE, 1, 1);

  scriptProcessor.onaudioprocess = event => {
    if (!isRecording) return;
    const samples = event.inputBuffer.getChannelData(0);
    pcmBuffers.push(new Float32Array(samples));
  };

  micSource.connect(scriptProcessor);
  scriptProcessor.connect(audioCtx.destination);

  isRecording   = true;
  setRecordingUI(true);
  recordTimeout = setTimeout(stopRecording, MAX_RECORD_SECONDS * 1000);
}

// â”€â”€ Stop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function stopRecording() {
  if (!isRecording) return;
  clearTimeout(recordTimeout);
  isRecording = false;
  setRecordingUI(false);

  // Disconnect graph but keep audioCtx and micStream alive â€” the OS mic
  // indicator stays on and auto-restart after TTS works without a user gesture.
  if (scriptProcessor) { scriptProcessor.disconnect(); scriptProcessor = null; }
  if (micSource)       { micSource.disconnect();       micSource = null; }

  processAndSend(pcmBuffers);
}

// â”€â”€ Merge â†’ resample â†’ WAV â†’ POST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function processAndSend(buffers) {
  if (!buffers.length) {
    setStatus('No audio captured â€” try again', 'error');
    return;
  }
  setStatus('Processingâ€¦', 'processing');

  // Merge all chunks
  const totalLen = buffers.reduce((n, b) => n + b.length, 0);
  const merged   = new Float32Array(totalLen);
  let off = 0;
  for (const b of buffers) { merged.set(b, off); off += b.length; }

  // Resample to 16 kHz
  const resampled = resample(merged, nativeSampleRate, TARGET_SAMPLE_RATE);

  // Encode as PCM-16 WAV
  const wavBlob = toWavBlob(resampled, TARGET_SAMPLE_RATE);

  // Send
  const form = new FormData();
  form.append('audio', wavBlob, 'recording.wav');

  try {
    const res  = await fetch('/voice/process', { method: 'POST', body: form });
    const data = await res.json();

    if (!res.ok) {
      setStatus('Server error: ' + (data.error || 'Unknown'), 'error');
      return;
    }

    $('transcriptionText').textContent = data.transcription || '(nothing recognised)';
    $('responseText').textContent      = data.response_text || '';

    // â”€â”€ Track email compose step â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _emailStep = data.email_step || null;

    // â”€â”€ Handle special intents â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if (data.intent === 'stop_reading') {
      // Instant cut (Web Speech watcher may have already done this, but be safe)
      _stopSpeechWatcher();
      if (_ttsAudio) { _ttsAudio.pause(); _ttsAudio.src = ''; _ttsAudio = null; }
      _setSpeakingUI(false);
      setStatus('âœ‹ Stopped Â· Tap ğŸ¤ to continue', 'idle');
      return;
    }

    if (data.intent === 'cancel_email') {
      _emailStep = null;
      if (data.audio_url) { playTTS(data.audio_url); return; }  // TTS onended auto-restarts
      setStatus('Email cancelled Â· Ready to listen', 'idle');
      startRecording();
      return;
    }

    // â”€â”€ Normal flow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // If nothing was heard (silence), just go back to ready state silently
    if (!data.transcription && data.intent === 'unknown') {
      setStatus('Ready Â· Tap ğŸ¤ to speak', 'idle');
      return;
    }
    // Show compose step as status hint
    const stepLabels = { to: 'ğŸ“§ Step 1/4 Â· Say recipient address', subject: 'ğŸ“ Step 2/4 Â· Say subject', body: 'ğŸ’¬ Step 3/4 Â· Say your message', confirm: 'âœ… Step 4/4 Â· Say "confirm" or "cancel"' };
    const statusMsg = _emailStep ? stepLabels[_emailStep] : ('Done â€¢ ' + (data.intent || 'â€”'));
    setStatus(statusMsg, _emailStep ? 'recording' : 'done');

    if (data.audio_url) playTTS(data.audio_url);
    if (data.intent === 'logout') {
      _releaseMic();
      setTimeout(() => { window.location.href = '/'; }, 2500);
    }

  } catch (err) {
    setStatus('Network error: ' + err.message, 'error');
    console.error(err);
  }
}

// â”€â”€ Resample (linear interpolation) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function resample(samples, fromRate, toRate) {
  if (fromRate === toRate) return samples;
  const outLen = Math.round(samples.length * toRate / fromRate);
  const out    = new Float32Array(outLen);
  const ratio  = fromRate / toRate;
  for (let i = 0; i < outLen; i++) {
    const pos  = i * ratio;
    const idx  = Math.floor(pos);
    const frac = pos - idx;
    out[i] = (samples[idx] ?? 0) + frac * ((samples[idx + 1] ?? 0) - (samples[idx] ?? 0));
  }
  return out;
}

// â”€â”€ PCM-16 WAV encoder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function toWavBlob(float32, sampleRate) {
  const numCh    = 1;
  const dataSize = float32.length * 2;
  const buf      = new ArrayBuffer(44 + dataSize);
  const view     = new DataView(buf);
  const str = (o, s) => { for (let i = 0; i < s.length; i++) view.setUint8(o + i, s.charCodeAt(i)); };

  str(0,  'RIFF');  view.setUint32(4,  36 + dataSize,          true);
  str(8,  'WAVE');  str(12, 'fmt ');
  view.setUint32(16, 16,                    true);   // PCM chunk
  view.setUint16(20, 1,                     true);   // PCM format
  view.setUint16(22, numCh,                 true);
  view.setUint32(24, sampleRate,            true);
  view.setUint32(28, sampleRate * numCh * 2, true);  // byte rate
  view.setUint16(32, numCh * 2,             true);   // block align
  view.setUint16(34, 16,                    true);   // bits per sample
  str(36, 'data');  view.setUint32(40, dataSize, true);

  let o = 44;
  for (let i = 0; i < float32.length; i++) {
    const s = Math.max(-1, Math.min(1, float32[i]));
    view.setInt16(o, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    o += 2;
  }
  return new Blob([buf], { type: 'audio/wav' });
}

// â”€â”€ Words that should cut TTS the instant they're spoken â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Mirrors server-side _STOP_EXACT + _CANCEL_EXACT, kept broad for the small model
const _INTERRUPT_WORDS = new Set([
  'stop','top','stock','shop','stuff','stoop','stored','sport','stomp',
  'quiet','quite','silence','silent','pause','paws','halt',
  'enough','shut','cancel','cancelled','council','console','abort','no','nope',
]);

// â”€â”€ Instant stop-watcher using Web Speech API (no server roundtrip) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function _startSpeechWatcher() {
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SR) return;   // browser doesn't support it â€” user must tap â¹ button

  _stopSpeechWatcher();   // kill any previous instance

  const recog = new SR();
  recog.lang            = 'en-US';
  recog.continuous      = true;
  recog.interimResults  = true;   // fire on partial results for fastest response
  recog.maxAlternatives = 3;

  recog.onresult = (event) => {
    if (!isSpeaking) { recog.stop(); return; }
    for (let i = event.resultIndex; i < event.results.length; i++) {
      for (let j = 0; j < event.results[i].length; j++) {
        const heard = event.results[i][j].transcript.toLowerCase().trim();
        for (const word of heard.split(/\s+/)) {
          if (_INTERRUPT_WORDS.has(word)) {
            _stopSpeechWatcher();
            // Instant cut â€” no server trip, no TTS response
            if (_ttsAudio) { _ttsAudio.pause(); _ttsAudio.src = ''; _ttsAudio = null; }
            _setSpeakingUI(false);
            // Go idle â€” do NOT auto-start recording (would immediately capture
            // silence / the tail of "stop" and trigger "I did not hear anything")
            setStatus('âœ‹ Stopped Â· Tap ğŸ¤ to continue', 'idle');
            return;
          }
        }
      }
    }
  };

  recog.onerror = (e) => {
    // 'no-speech' is normal â€” just restart
    if (isSpeaking && e.error === 'no-speech') {
      setTimeout(() => { if (isSpeaking) _startSpeechWatcher(); }, 50);
    }
  };

  recog.onend = () => {
    // Auto-restart while TTS is still playing (browser stops after a few secs)
    if (isSpeaking && _wsRecog === recog) {
      setTimeout(() => { if (isSpeaking) _startSpeechWatcher(); }, 50);
    }
  };

  try { recog.start(); _wsRecog = recog; }
  catch (e) { console.warn('SpeechRecognition start error:', e); }
}

function _stopSpeechWatcher() {
  if (_wsRecog) { try { _wsRecog.stop(); } catch (_) {} _wsRecog = null; }
}

// â”€â”€ TTS playback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function playTTS(url) {
  if (_ttsAudio) { _ttsAudio.pause(); _ttsAudio.src = ''; _ttsAudio = null; }

  const a = $('ttsAudio');
  a.src = url + '?t=' + Date.now();
  _ttsAudio = a;

  _setSpeakingUI(true);

  a.onended = () => {
    _ttsAudio = null;
    _stopSpeechWatcher();
    _setSpeakingUI(false);
    // Only auto-start if TTS completed naturally (not interrupted by stop)
    // A 400ms grace delay avoids immediately capturing end-of-speech noise
    setTimeout(() => { if (!isRecording && !isSpeaking) startRecording(); }, 400);
  };
  a.onerror = () => {
    _ttsAudio = null;
    _stopSpeechWatcher();
    _setSpeakingUI(false);
    setTimeout(() => { if (!isRecording && !isSpeaking) startRecording(); }, 400);
  };

  a.play()
    .then(() => {
      // Start instant stop-watcher the moment audio begins
      _startSpeechWatcher();
    })
    .catch(e => {
      console.warn('TTS play error:', e);
      _setSpeakingUI(false);
    });
}

// Called by â¹ button or toggleRecording() while speaking
function stopSpeaking() {
  _stopSpeechWatcher();
  if (_ttsAudio) { _ttsAudio.pause(); _ttsAudio.src = ''; _ttsAudio = null; }
  _setSpeakingUI(false);
  // Go idle â€” user taps mic when ready for next command
  setStatus('âœ‹ Stopped Â· Tap ğŸ¤ to continue', 'idle');
}

// Call this only on explicit logout to release the OS mic indicator
function _releaseMic() {
  _stopSpeechWatcher();
  if (scriptProcessor) { scriptProcessor.disconnect(); scriptProcessor = null; }
  if (micSource)       { micSource.disconnect();       micSource = null; }
  if (micStream)       { micStream.getTracks().forEach(t => t.stop()); micStream = null; }
  if (audioCtx)        { audioCtx.close();             audioCtx = null; }
}

// â”€â”€ Speaking UI helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function _setSpeakingUI(speaking) {
  isSpeaking = speaking;
  const micBtn  = $('micBtn');
  const stopBtn = $('stopBtn');
  const sr1     = $('speakRing1');
  const sr2     = $('speakRing2');

  if (speaking) {
    // Mic stays visible but dimmed â€” user can click it to interrupt + record
    micBtn.classList.add('opacity-50', 'scale-90');
    stopBtn.classList.remove('hidden');
    sr1 && sr1.classList.remove('hidden');
    sr2 && sr2.classList.remove('hidden');
    setStatus('ğŸ”Š Speakingâ€¦ say "stop" or tap ğŸ¤', 'processing');
  } else {
    micBtn.classList.remove('opacity-50', 'scale-90');
    stopBtn.classList.add('hidden');
    sr1 && sr1.classList.add('hidden');
    sr2 && sr2.classList.add('hidden');
  }
}

// â”€â”€ UI helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function setRecordingUI(on) {
  const btn = $('micBtn');
  if (on) {
    btn.classList.add('recording');
    btn.innerHTML = 'â¹';
    $('ring1').classList.remove('hidden');
    $('ring2').classList.remove('hidden');
    setStatus(`Recordingâ€¦ (auto-stops in ${MAX_RECORD_SECONDS}s)`, 'recording');
  } else {
    btn.classList.remove('recording');
    btn.innerHTML = 'ğŸ¤';
    $('ring1').classList.add('hidden');
    $('ring2').classList.add('hidden');
  }
}

function setStatus(msg, type = 'idle') {
  const colors = { idle:'text-gray-400', recording:'text-red-400', processing:'text-yellow-400', done:'text-green-400', error:'text-red-500' };
  const el = $('statusText');
  el.className  = 'text-center text-sm mt-2 ' + (colors[type] || colors.idle);
  el.textContent = msg;
}
// Release mic tracks when page closes / navigates away
window.addEventListener('beforeunload', _releaseMic);